{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.context import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "sc = pyspark.SparkContext('local[*]') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios propuestos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 1**: Escribir una UDF que convierta en minúsculas excepto el primer caracter de la columna *des_nomco* del dataframe *ttgoficiDF* cargado a continuación: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "dataPath = \"../data/ttgofici.csv\"\n",
    "ttgoficiDF = sqlContext.read.format(\"com.databricks.spark.csv\")\\\n",
    "            .option(\"header\", \"true\")\\\n",
    "            .load(dataPath)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 2**: Desarrollar una \"UDF\" que convierta el primer caracter de un string según la siguiente regla:  \n",
    "'1'-> 'a'  \n",
    "'2'-> '1'  \n",
    "'3'-> '2'  \n",
    "'4'-> '3'  \n",
    "'5'-> '4'  \n",
    "'6'-> '5'  \n",
    "'7'-> '6'  \n",
    "'8'-> '7'  \n",
    "De tal forma un String con valor: \"1.Semana del 1 al 7 de agosto\" se convertirá a : \"a..Semana del 1 al 7 de   agosto\", \"2.Semana del 8 al 14 de agosto\" se convertirá a \"1.Semana del 8 al 14 de agosto\"... y así sucesivamente.  \n",
    "Tip: utilizar el siguiente mapping:  \n",
    "mapping = {'1': 'a', '2': '1', '3': '2', '4': '3', '5': '4', '6': '5', '7': '6', '8':'7'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [('1', '1.Semana del 1 al 7 de agosto'),('2', '2.Semana del 8 al 14 de agosto'),\\\n",
    "     ('3', '3.Semana del 15 al 21 de agosto'),('4', '3.Semana del 15 al 21 de agosto')]\n",
    "DFSpentData =  sqlContext.createDataFrame(data, ['id','Semana'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 3**: Migrar las siguientes transformaciones en lenguaje a SAS a SparkSQL:\n",
    "\n",
    "data inframul_diaria;  \n",
    "\tset diaria.Nuevanet_di_con;  \n",
    "\n",
    "\tdia = substr(FEC_ULTACCSO,9,2);  \n",
    "\tmes = substr(FEC_ULTACCSO,6,2);  \n",
    "\tanio= substr(FEC_ULTACCSO,1,4);  \n",
    "\tfecha = compress(anio||mes||dia);  \n",
    "\tformat fecha_ult_conexion_semanal date9.;  \n",
    "\tfecha_ult_conexion_semanal =input(fecha, yymmdd10.);  \n",
    "\tcod_persona = input (COD_PERSCTPN, 11.);  \n",
    "run;\n",
    "\n",
    "proc sql;  \n",
    "\tcreate table cli_net_semanal as  \n",
    "\tselect distinct cod_persona,  \n",
    "\t\t\tmax (fecha_ult_conexion_semanal) as fecha_ult_conexion_semanal format date9.  \n",
    "\tfrom inframul_diaria  \n",
    "\twhere fecha_ult_conexion_semanal>=&FEC_INI02  \n",
    "\tgroup by cod_persona \n",
    "\torder by cod_persona;  \n",
    "quit;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
