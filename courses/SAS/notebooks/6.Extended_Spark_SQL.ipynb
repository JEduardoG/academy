{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../static/logo.png\" alt=\"datio\" style=\"width: 200px \"align=\"right\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Spark UDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining our udf is pretty easy, we just create an anonymous function and register it through the SqlContext or through the udf function in org.apache.spark.sql.functions.udf depending on how you want to use it.  \n",
    "UDF operates on distributed DataFrames and works row by row.  \n",
    "\n",
    "As a montivating example assume we want to convert a String Column \"f-cierre\" with date information divided in year, month and day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.context import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "sc = pyspark.SparkContext('local[*]') \n",
    "sqlContext = SQLContext(sc)\n",
    "# We are going to work with a the data Ttgofici\n",
    "dataPath = \"../data/\"\n",
    "customSchema = StructType([\n",
    " StructField(\"cod_bancsb\",  StringType(), True),\n",
    " StructField(\"cod_ofici\",  IntegerType(), True),\n",
    " StructField(\"cnivel\",  StringType(), True),\n",
    " StructField(\"cod_zona\",  StringType(), True),\n",
    " StructField(\"cod_territor\",  StringType(), True),\n",
    " StructField(\"cod_dirgener\",  StringType(), True),\n",
    " StructField(\"cod_areanego\",  IntegerType(), True),\n",
    " StructField(\"cod_dar\",  StringType(), True),\n",
    " StructField(\"des_nomco\",  StringType(), True),\n",
    " StructField(\"des_nomab\",  StringType(), True),\n",
    " StructField(\"f_cierre\",  StringType(), True),\n",
    " StructField(\"cod_cbc\",  StringType(), True)])\n",
    "\n",
    "ttgoficiDF = sqlContext.read.format(\"com.databricks.spark.csv\")\\\n",
    "            .option(\"header\", \"true\")\\\n",
    "            .load(dataPath + \"ttgofici.csv\", schema=customSchema)\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "getDay = UserDefinedFunction(lambda x: x[8:10], StringType())\n",
    "getMonth = UserDefinedFunction(lambda x: x[5:7], StringType())\n",
    "getYear = UserDefinedFunction(lambda x: x[0:4], StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ttgoficiDF2 = ttgoficiDF\\\n",
    ".withColumn(\"dia\",getDay(\"f_cierre\"))\\\n",
    ".withColumn(\"mes\",getMonth(\"f_cierre\"))\\\n",
    ".withColumn(\"anio\",getYear(\"f_cierre\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ttgoficiDF2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ttgoficiDF2.registerTempTable(\"TtgoficiDMY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register UDF in sparksql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to register a function as a UDF so it can be used in SQL statements.  \n",
    "\n",
    "registerFunction(name, f, returnType=StringType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Register an anonymous function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Syntax  \n",
    "\n",
    "    The syntax of lambda functions contains only a single statement, which is as follows −  \n",
    "\n",
    "    lambda [arg1 [,arg2,.....argn]]:expression  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext.registerFunction(\"getDay\", lambda x: x[8:10], StringType())\n",
    "sqlContext.registerFunction(\"getMonth\", lambda x: x[5:7], StringType())\n",
    "sqlContext.registerFunction(\"getYear\", lambda x: x[0:4], StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext.registerDataFrameAsTable(ttgoficiDF,\"ttgoficiDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use our function directly in SparkSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext.sql(\"select *, getDay(f_cierre) as dia, getMonth(f_cierre) as mes, getYear(f_cierre) as anio \\\n",
    "from ttgoficiDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Register a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Syntax  \n",
    "\n",
    "    def functionname( parameters ):  \n",
    "       \"function_docstring\"  \n",
    "       function_suite  \n",
    "       return [expression]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def includePref(value, pref ) : return pref + value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext.registerFunction(\"includePref\",includePref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext.sql(\"select *, includePref(cnivel, 'C-') as cnivel from ttgoficiDF\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# but not outside\n",
    "ttgoficiDF.withColumn(\"cnivel2\",udfincludePref(col(\"cnivel\"), lit(\"C-\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see above that we can use it within SQL but not outside of it.  \n",
    "To do that we're going to have to create a different UDF using:\n",
    "spark.sql.function.udf wich returns a UDFRegistration for UDF registration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf,lit,col\n",
    "udfincludePref = udf(includePref, StringType())\n",
    "#now this works\n",
    "ttgoficiDF.withColumn(\"cnivel2\",udfincludePref(\"cnivel\", lit(\"C-\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio  1: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadir al dataframe ttgoficiDF una nueva columna denominada \"area\", según el avalor de cod_territor, de tal forma:  \n",
    "    con_territor >= 8000 -> area = A  \n",
    "    con_territor >= 6000 -> area = B  \n",
    "    con_territor >= 4000 -> area = C  \n",
    "    con_territor <  4000 -> area = D  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def codTerritorToArea(cod_territor):\n",
    "    territor = int(cod_territor)\n",
    "    if territor >= 8000: return 'A'\n",
    "    elif territor >= 6000: return 'B'\n",
    "    elif territor >= 4000: return 'C'\n",
    "    else: return 'D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "udfcodTerritorToArea=udf(codTerritorToArea, StringType())\n",
    "ttgoficiDF.withColumn(\"area\", udfcodTerritorToArea(\"cod_territor\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar la misma funcionalidad mediante secuencia sql: case..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
