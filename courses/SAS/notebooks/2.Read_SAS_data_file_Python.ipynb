{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../static/logo.png\" alt=\"datio\" style=\"width: 200px \"align=\"right\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ SAS DATA FILE WITH SAS7BDAT AND SAVE TO CSV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will read sas7bdat files using pure Python (2.6+, 3+). No SAS software required!\n",
    "The project was originally based off the work done by Matt Shotwell and Clint Cummins in their R project found at https://github.com/BioStatMatt/sas7bdat but has since been completely rewritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../lib/\")\n",
    "from sas7bdat import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read SAS file and instantiate the sas7bdat class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#File from nces: http://nces.ed.gov/ccd/Data/zip/ag121a_supp_sas.zi\n",
    "nameFile = \"ag121a_supp\"\n",
    "inFile = \"../data/\" + nameFile + \".sas7bdat\"\n",
    "data = SAS7BDAT(inFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a pandas Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = data.to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Visualize df\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Getting columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Getting the number of rows:\n",
    "len(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converts sas7bdat files to csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sas7bdat script -> Convert sas7bdat files to csv. <infile> is the path to a sas7bdat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run ../lib/sas7bdat_to_csv ../data/*.sas7bdat "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRANSFORM SAS FILES TO PARQUET THROUGHT SPARK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have transformed a SAS sas7bdat file to a pandas DataFrame. The great thing in Spark is that a Python/pandas DataFrame could be translated to Spark DataFrame by the createDataFrame method. Now I have two DataFrames: one is a pandas DataFrame and the other is a Spark DataFrame\n",
    "\n",
    "The strategy is to build a pipeline to realize my purpose such as SAS --> Python --> Spark --> Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with SAS7BDAT(inFile) as f:\n",
    "     pandas_df = f.to_data_frame()\n",
    "print('-----Data in Pandas dataframe-----')\n",
    "print(pandas_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.context import SQLContext\n",
    "sc = pyspark.SparkContext('local[*]')\n",
    "sqlContext = SQLContext(sc)\n",
    "print('-----Data in Spark dataframe-----')\n",
    "spark_df = sqlContext.createDataFrame(pandas_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two dataframes should be the identical length. Here both show 1838 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(pandas_df))\n",
    "print(spark_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " To write in parquet format: **df.write.save()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark_df.write.save(path = \"../data/\" + nameFile, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automate the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sas_to_parquet(filelist, destination):\n",
    "    \"\"\"Save SAS file to parquet\n",
    "    Args:\n",
    "        filelist (list): the list of sas file names\n",
    "        destination (str): the path for parquet\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    rows = 0\n",
    "    for i, filename in enumerate(filelist):\n",
    "        with SAS7BDAT(filename) as f:\n",
    "            pandas_df = f.to_data_frame()\n",
    "            rows += len(pandas_df)\n",
    "        spark_df = sqlContext.createDataFrame(pandas_df)\n",
    "        spark_df.write.save(destination +  i + \".parquet\")\n",
    "    print('{0} rows have been transformed'.format(rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages of Parquet Version\n",
    "- Self-describing   \n",
    "- Columnar format (very efficient compression)   \n",
    "- Language-independent  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
